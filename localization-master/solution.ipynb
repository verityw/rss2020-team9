{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Writing Assignment\n",
    "\n",
    "<a id='question1'></a>\n",
    "**Question 1**. (**Motion Model**) Consider a deterministic motion model (no added noise) based on odometry information. The motion model, $g$, takes as arguments the old particle pose, $\\mathbf{x}_{t-1}$, as well as the current odometry data, $\\Delta\\mathbf{x}$, and returns a new pose, $\\mathbf{x}_t$ with the odometry “applied” to the old poses:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{x}_t = \\begin{bmatrix}x_t\\\\y_t\\\\\\theta_t\\end{bmatrix} = g(\\mathbf{x}_{t-1}, \\Delta x)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that the poses $\\mathbf{x}$ are expressed in the world frame relative to some arbitrary origin. The odometry $\\Delta \\mathbf{x}$ is necessarily a local quantity, expressed relative to the previous frame.\n",
    "\n",
    "**i** Suppose you are given $\\mathbf{x}_{t-1} = \\left[0, 0, \\frac{\\pi}{6}\\right]^T$ and $\\mathbf{x}_{t} = \\left[0.2, 0.1, \\frac{11\\pi}{60}\\right]^T$. Compute the odometry data $\\Delta \\mathbf{x}$ that results in this transformation.\n",
    "\n",
    "**ii**. Now suppose you received the odometry data $\\Delta\\mathbf{x}$ from part **i**, but your car was previously at position $\\mathbf{x}_{t-1} = \\left[3, 4, \\frac{\\pi}{3}\\right]^T$. Compute the current pose $\\mathbf{x}_t$.\n",
    "\n",
    "If you were to use this deterministic motion model in your particle filter all of your particles would end up in the same place - which defeats the purpose of having so many. When you build your actual motion model, you will be injecting noise into the function $g$ which will make your particles spread out as the car moves. This accounts for any uncertainty that exists in the odometry information. The sensor model will collapse this spreading of particles back into a small region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "i. The estimated change of pose $\\Delta \\mathbf{x}$ is actually the pose at time $t$ in the body frame at time $t-1$.\n",
    "\n",
    "The transform from body frame to world frame $T^{B}_{W}$, is equal to the inverse of the vehicle's pose in the world frame $\\mathbf{x}^{W}_{t-1} = <x_{t-1}, y_{t-1}, \\theta_{t-1}>$. \n",
    "\n",
    "$$\n",
    "T^{B}_{W} = (T^{W}_{B})^{-1} = \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{R}_{t-1} & \\mathbf{P}_{t-1}\\\\\n",
    "\\mathbf{0} & 1\n",
    "\\end{bmatrix}^{-1}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{R}^{-1}_{t-1} & -\\mathbf{R}_{t-1}^{-1}\\mathbf{P}_{t-1}\\\\\n",
    "\\mathbf{0} & 1\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta_{t-1} & \\sin\\theta_{t-1} & -(x_{t-1}\\cos\\theta_{t-1} + y_{t-1}\\sin\\theta_{t-1}) \\\\\n",
    "-\\sin\\theta_{t-1} & \\cos\\theta_{t-1} & -(-x_{t-1}\\sin\\theta_{t-1} + y_{t-1}\\cos\\theta_{t-1}) \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$T^{B}_W$ brings pose at time $t$ in world frame to body frame:\n",
    "$$\n",
    "\\Delta \\mathbf{x}^{B} = T_{W}^{B} \\cdot \\mathbf{x}_{t}^{W} = \\begin{bmatrix}\n",
    "\\cos\\theta_{t-1} & \\sin\\theta_{t-1} & -(x_{t-1}\\cos\\theta_{t-1} + y_{t-1}\\sin\\theta_{t-1}) \\\\\n",
    "-\\sin\\theta_{t-1} & \\cos\\theta_{t-1} & -(-x_{t-1}\\sin\\theta_{t-1} + y_{t-1}\\cos\\theta_{t-1}) \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta_t & -\\sin \\theta_t & x_t\\\\\n",
    "\\sin\\theta_t & \\cos \\theta_t & y_t \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Plug in the values provided and convert resulting matrix to vector form, we find $\\Delta \\mathbf{x}^{B} = <0.223, -0.0134, 0.0524>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code from last year: odom_msg: [ 0.22320508 -0.01339746  0.05235988]\n",
      "Algorithm from p-book: odom_msg [ 0.22320508 -0.01339746  0.05235988]\n",
      "Code using transform matrix: odom_msg [ 0.22320508 -0.01339746  0.05235988]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt, pi, cos, sin, atan2, atan \n",
    "\n",
    "# ----------- help function --------------------\n",
    "def rotation_matrix(theta):\n",
    "    return np.array([[cos(theta), -sin(theta)], [sin(theta), cos(theta)]])\n",
    "\n",
    "def dist(dx, dy):\n",
    "    return sqrt(dx*dx + dy*dy)\n",
    "\n",
    "def pose_matrix_from_vec(pose_vec):\n",
    "    x = pose_vec[0]\n",
    "    y = pose_vec[1]\n",
    "    theta = pose_vec[2]\n",
    "    return np.array([[cos(theta), -sin(theta), x], [sin(theta), cos(theta), y], [0, 0, 1]])\n",
    "# ----------- help function --------------------\n",
    "\n",
    "\n",
    "'''\n",
    "finddx:\n",
    "    Calculate deltas between consecutive odometry messages in the coordinate space of the car.\n",
    "    \n",
    "Three possible solutions are given below.\n",
    "'''\n",
    "def finddx_pbook(last_pose, cur_pose):\n",
    "    '''\n",
    "    Solution from Probabilistic Robotics\n",
    "    '''\n",
    "    assert(isinstance(last_pose, np.ndarray))\n",
    "    \n",
    "    dx = cur_pose[0] - last_pose[0]\n",
    "    dy = cur_pose[1] - last_pose[1]\n",
    "\n",
    "    delta_rot1 = atan2(dy, dx) - last_pose[2]\n",
    "    delta_trans = dist(dx, dy) \n",
    "    delta_rot2 = cur_pose[2] - last_pose[2] - delta_rot1\n",
    "\n",
    "    return np.array([delta_trans * cos(delta_rot1), delta_trans * sin(delta_rot1), delta_rot1+delta_rot2])\n",
    "\n",
    "def finddx_2018(last_pose, cur_pose):\n",
    "    '''\n",
    "    Solution from previous year\n",
    "    '''\n",
    "    assert(isinstance(last_pose, np.ndarray))\n",
    "    \n",
    "    rot = rotation_matrix(-last_pose[2])\n",
    "    delta = np.array([cur_pose[0:2]- last_pose[0:2]]).transpose()\n",
    "    local_delta = (np.dot(rot,delta)).transpose()\n",
    "    assert(local_delta.shape == (1, 2))\n",
    "    return np.array([local_delta[0,0], local_delta[0,1], cur_pose[2]- last_pose[2]])\n",
    "\n",
    "def finddx_matrix(last_pose, cur_pose):\n",
    "    '''\n",
    "    Solution using transform matrix\n",
    "    '''\n",
    "    assert(isinstance(last_pose, np.ndarray))\n",
    "    assert(isinstance(cur_pose, np.ndarray))\n",
    "    \n",
    "    T_BW = np.linalg.inv(pose_matrix_from_vec(last_pose))\n",
    "    dx_W = pose_matrix_from_vec(cur_pose)\n",
    "\n",
    "    res = np.dot(T_BW, dx_W)\n",
    "    delta_theta_B = atan(res[1][0]/res[0][0]) \n",
    "\n",
    "    return np.array([res[0][2], res[1][2], delta_theta_B]) \n",
    "\n",
    "last_pose = np.array([0.0, 0.0, pi/6.0])\n",
    "cur_pose = np.array([0.2, 0.1, pi * 11.0 / 60.0])\n",
    "\n",
    "\n",
    "print('Code from last year: odom_msg:', finddx_2018(last_pose, cur_pose))\n",
    "print('Algorithm from p-book: odom_msg', finddx_pbook(last_pose, cur_pose))\n",
    "print('Code using transform matrix: odom_msg', finddx_matrix(last_pose, cur_pose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. \n",
    "Again, we can easiy find the updated pose from transform matrix. \n",
    "$$\n",
    "\\mathbf{x}^{W}_t = T^{W}_{B} \\cdot \\Delta\\mathbf{x}^B\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_t in world frame (pbook): [3.12320508 4.18660254 1.09955743]\n",
      "x_t in world frame (code from last year): [3.12320508 4.18660254 1.09955743]\n",
      "x_t in world frame (transform matrix): [3.12320508 4.18660254 1.09955743]\n"
     ]
    }
   ],
   "source": [
    "odom_msg = finddx_pbook(last_pose, cur_pose)\n",
    "x_prev = np.array([3, 4, pi/3.0])\n",
    "\n",
    "'''\n",
    "Odometry data is accumulated via dead reckoning, so it is very inaccurate on its own.\n",
    "We apply the pose update from odometry measurement on the pose (estimated from last time step)\n",
    "\n",
    "Three possible solutions are given below.\n",
    "'''\n",
    "def apply_odom_pbook(x_prev, odom_msg):\n",
    "    dx = odom_msg[0]\n",
    "    dy = odom_msg[1]\n",
    "    dtheta = odom_msg[2]\n",
    "    dr = sqrt(dx*dx + dy*dy)\n",
    "    \n",
    "    delta_rot1 = atan2(dy, dx)\n",
    "    xt = x_prev[0] + dr * cos(x_prev[2] + delta_rot1)\n",
    "    yt = x_prev[1] + dr * sin(x_prev[2] + delta_rot1)\n",
    "    thetat = x_prev[2] + dtheta\n",
    "    \n",
    "    return np.array([xt, yt, thetat])\n",
    "   \n",
    "def apply_odom_2018(x_prev, odom_msg):\n",
    "    cosines = np.cos(x_prev[2])\n",
    "    sines = np.sin(x_prev[2])\n",
    "\n",
    "    local_deltas = np.zeros(3)\n",
    "    local_deltas[0] = cosines*odom_msg[0] - sines*odom_msg[1]\n",
    "    local_deltas[1] = sines*odom_msg[0] + cosines*odom_msg[1]\n",
    "    local_deltas[2] = odom_msg[2]\n",
    "    \n",
    "    return x_prev + local_deltas\n",
    "\n",
    "def apply_odom_matrix(x_prev, odom_msg):\n",
    "    x_t = np.dot(pose_matrix_from_vec(x_prev), pose_matrix_from_vec(odom_msg))\n",
    "    \n",
    "    return np.array([x_t[0][2], x_t[1][2], atan(x_t[1][0]/x_t[0][0])])\n",
    "\n",
    "print('x_t in world frame (pbook):', apply_odom_pbook(x_prev, odom_msg))\n",
    "print('x_t in world frame (code from last year):', apply_odom_2018(x_prev, odom_msg))\n",
    "print('x_t in world frame (transform matrix):', apply_odom_matrix(x_prev, odom_msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='question2'></a>\n",
    "**Question 2**. (**Sensor Model**) The sensor model, $p\\left(z_{t}| x_{t}, m\\right)$, defines how likely it is to record a given sensor reading $z_{t}$ from a hypothesis position $x_{t}$ in a known, static map $m$ at time $t$. We will use this likelihood to \"prune\" the particles as the motion model tries to spread them out. Particles will be kept if the sensor reading is consistent with the map from the point of view of that particle. The definition of this likelihood is strongly dependent on the type of sensor used - a laser scanner in our case.\n",
    "\n",
    "In a lidar model, typically, there are a few cases to be modeled in determining $p\\left(z_{t}| x_{t}, m\\right)$:\n",
    "\n",
    "1. Probability of detecting a known obstacle in the map\n",
    "2. Probability of a short measurement. Maybe due to internal lidar reflections (scratches or oils on the surface), hitting parts of the vehicle itself, or other unknown obstacles (people, cats, etc).\n",
    "3. Probability of a very large (aka missed) measurement. Usually due to lidar beams that hit an object with strange reflective properties and did not bounce back to the sensor\n",
    "4. Probability of a completely random measurement. Just in case of an asteroid strike.\n",
    "    \n",
    "We typically represent (1) with a gaussian distribution centered around the ground truth distance between the hypothesis pose and the nearest map obstacle. Thus, if the measured range exactly matches the expected range, the probability is maximum. If the measured range is $z_{t}$ and the ground truth range is determined (via ray casting on the map $m$ from pose $x_t$) to be $z_{t}^*$ then we have that:\n",
    "\n",
    "$$\n",
    "\tp_{hit}(z_{t}| x_{t}, m)  = \\begin{cases}\n",
    "\t\\eta \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(z_t - z_t^*)^2}{2\\sigma^2}\\right)  &   \\text{if} \\quad 0 \\leq z_{t}^{k} \\leq z_{max}\\\\\n",
    "    0   &   \\text{otherwise}\n",
    "    \\end{cases}\n",
    "$$\n",
    "where $\\eta$ is a normalization constant need to be determined.\n",
    "\n",
    "Case (2) is represented as a downward sloping line as the ray gets further from the robot.\n",
    "This is because if the unknown obstacles (people cats, etc.) are distributed uniformly in the environment, the lidar is more likely to hit ones that are closer (think about how area scales...). This likelihood can be modeled as:\n",
    "\n",
    "$$\n",
    "\tp_{short}\\left(z_{t}| x_{t}, m\\right) =  \\frac{2}{z_t^*} \\begin{cases}\n",
    "         1 - \\frac{z_{t}}{z_{t}^*}   &   \\text{if} \\quad 0 \\leq z_{t}^{k} \\leq z_{t}^*\\\\\n",
    "         0   &   \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Case (3) is represented by a large spike in probability at the maximal range value, so that reflected measurements do not significantly discount particle weights.\n",
    "\n",
    "$$\n",
    "\tp_{max}(z_{t}| x_{t}, m)  =\\begin{cases}\n",
    "\t1  &  \\text{if} \\quad z_t = z_{max}\\\\\n",
    "\t0  &  \\text{otherwise} \n",
    "\t\\end{cases}\n",
    "\t$$\n",
    "\n",
    "Case (4) is represented by a small uniform value, to account for unforeseen effects.\n",
    "\n",
    "$$\n",
    "\tp_{rand}(z_{t}| x_{t}, m)  = \\begin{cases}\n",
    "\t\\frac{1}{z_{max}}  &  \\text{if} \\quad 0\\leq z_{t} < z_{max}\\\\\n",
    "\t0                            & \\text{otherwise} \n",
    "\t\\end{cases}\n",
    "$$\n",
    "\t\n",
    "These four different distributions are now mixed by a weighted average, defined by the parameters $\\alpha_{hit}, \\alpha_{short},\\alpha_{max},\\alpha_{rand}$:\n",
    "\n",
    "$$\n",
    "\t p(z_{t}| x_{t}, m)  = \\alpha_{hit} \\cdot p_{hit}(z_{t}| x_{t}, m)  + \\alpha_{short} \\cdot p_{short}(z_{t}| x_{t}, m)  + \\alpha_{max} \\cdot p_{max}(z_{t}| x_{t}, m)  + \\alpha_{rand} \\cdot p_{rand}(z_{t}| x_{t}, m) \n",
    "$$\n",
    "\n",
    "Note that in order for $p(z_{t}| x_{t}, m)$ to be a probability distrubution we have have that:\n",
    "\n",
    "$$\n",
    "\\alpha_{hit}+\\alpha_{short}+\\alpha_{max}+\\alpha_{rand}=1\n",
    "$$\n",
    "\n",
    "\t \n",
    "Find the values of $p(z_{t} | x_{t}, m)$ for the values of $z_t$ below and the following parameters:\n",
    "$\\alpha_{hit} = 0.74$,\n",
    "$\\alpha_{short}=0.07$,\n",
    "$\\alpha_{max}=0.07$,\n",
    "$\\alpha_{rand}=0.12$,\n",
    "$\\sigma=0.5\\text{ m}$\n",
    "$z_{max}=10\\text{ m}$, and\n",
    "$z_{t}^{*} = 7\\text{ m}$.\n",
    "\n",
    "**i**.    $z_{t} = 0\\text{ m}$\n",
    "\n",
    "**ii**.   $z_{t} = 3\\text{ m}$\n",
    "\n",
    "**iii**.  $z_{t} = 5\\text{ m}$\n",
    "\n",
    "**iv**.   $z_{t} = 8\\text{ m}$\n",
    "\n",
    "**v**.    $z_{t} = 10\\text{ m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "The required values $p(z_t|x_t, m)$ are probability density function (pdf, for continuous variables), we need to convert them to probability values in the precomupted table. Interestingly, if we work on the 'table space', the discretized size will be 1, and the values of pdf are equal to the values of probability.\n",
    "\n",
    "See the `sensor_model.py` file for a completed version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 0.000000 pdf: 0.032000\n",
      "r: 3.000000 pdf: 0.023429\n",
      "r: 5.000000 pdf: 0.017912\n",
      "r: 8.000000 pdf: 0.091907\n",
      "r: 10.000000 pdf: 0.070000\n"
     ]
    }
   ],
   "source": [
    "def sensor_model(d, r):\n",
    "    '''\n",
    "    The sensor model. For each discrete computed range value, this provides the probability \n",
    "    of measuring any (discrete) range.\n",
    "    \n",
    "    Argc:\n",
    "        d: computed range from RangeLibc\n",
    "        r: the observed range from the lidar unit\n",
    "    Return:\n",
    "        prob: the probability of observing r \n",
    "            conditioning on computed range and predefined map\n",
    "    '''\n",
    "    # sensor model constants\n",
    "    alpha_hit = 0.74\n",
    "    alpha_short = 0.07\n",
    "    alpha_max = 0.07\n",
    "    alpha_rand = 0.12\n",
    "    \n",
    "    sigma_hit = 0.5 \n",
    "    c_r = 0.01\n",
    "    \n",
    "    MAX_RANGE_METER = 10\n",
    "    # MAX_RANGE_PX = 200\n",
    "    \n",
    "    prob = 0.0\n",
    "    z = float(r-d)\n",
    "    # reflects from the intended object\n",
    "    # nomalization constant \\eta is approximated as 1 in this case\n",
    "    prob +=  alpha_hit * np.exp(-(z*z)/(2.0*sigma_hit*sigma_hit)) / (sigma_hit * np.sqrt(2.0*np.pi))\n",
    "\n",
    "    # observed range is less than the predicted range - short reading\n",
    "    if r < d:\n",
    "        prob += alpha_short * 2.0/d * (d - r) / float(d)\n",
    "\n",
    "    # erroneous max range measurement\n",
    "    if int(r) == int(MAX_RANGE_METER):\n",
    "        prob += alpha_max\n",
    "\n",
    "    # random measurement\n",
    "    if r < int(MAX_RANGE_METER):\n",
    "        prob += alpha_rand * 1.0/float(MAX_RANGE_METER)\n",
    "\n",
    "    return prob\n",
    "\n",
    "# d is the computed range from RangeLibc\n",
    "d = 7 \n",
    "# r is the observed range from the lidar unit\n",
    "rlist = [0, 3, 5, 8, 10]\n",
    "for r in rlist:\n",
    "    prob = sensor_model(d, r)\n",
    "    print('r: %f' % r, 'pdf: %f'% prob)\n",
    "    \n",
    "# Visualization the pdf\n",
    "MAX_RANGE_METER = 10\n",
    "rmin = 0\n",
    "rmax = MAX_RANGE_METER\n",
    "num = 1000\n",
    "rlist = np.linspace(rmin, rmax, num)\n",
    "pdf = [sensor_model(d, r) for r in rlist]\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(rlist, pdf)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
